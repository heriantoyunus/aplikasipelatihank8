{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dnuNpwJkN1h"
   },
   "source": [
    "# TUGAS AKHIR MODUL 14 : Membangun Model ANN\n",
    "# Kelas UG04 Kelompok 8\n",
    "1.\t05124873131-20/Herianto\n",
    "2.\t05124873011-21/Dinaroe\n",
    "3.\t05124873181-3/Fadhli Dzil Ikram\n",
    "\n",
    "Judul Tugas Akhir :\n",
    "**Upaya Meningkatkan Jumlah Mahasiswa Aktif di Perguruan Tinggi Swasta dengan Cara Membangun Sistem Untuk Mengidentifikasi Sedini Mungkin Calon Mahasiswa Baru atau Mahasiswa Lama Yang Berpotensi Keluar**\n",
    "\n",
    "Sumber dataset : **Database Sistem Akademik Universitas Darma Persada Jakarta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgRfUxh232lI"
   },
   "source": [
    "Dataset yang digunakan dalam Notebook ini adalah dataset daftar calon mahasiswa dari database akademik yang sebelumnya sudah dilakukan beberapa proses di tahap data preparation\n",
    "Dataset dapat di-load dengan potongan kode di bawah:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 0.85714286, 0.3       , 0.95906038],\n",
       "       [0.5       , 0.        , 0.        , 0.3       , 0.95906038],\n",
       "       [0.5       , 0.        , 0.42857143, 0.3       , 0.95906038],\n",
       "       ...,\n",
       "       [0.5       , 0.        , 0.14285714, 0.2       , 0.86923804],\n",
       "       [0.5       , 0.        , 0.        , 0.3       , 0.86923804],\n",
       "       [0.5       , 0.        , 0.14285714, 0.3       , 0.86923804]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_klasifikasi=pd.read_csv(\"..\\dataset\\dataset_pendaftar_clean_klasifikasi.csv\")\n",
    "#Featureg\n",
    "Xy=df_klasifikasi[['sedang_promo','sedang_ptn','idjenissekolah','idpend_ayah','ekonomi_nasional','isdaftarulang']]\n",
    "X=df_klasifikasi[['sedang_promo','sedang_ptn','idjenissekolah','idpend_ayah','ekonomi_nasional']]\n",
    "scale = MinMaxScaler()\n",
    "X = scale.fit_transform(X)\n",
    "\n",
    "#Target\n",
    "y=df_klasifikasi['isdaftarulang']\n",
    "Xy\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (5688, 5)\n",
      "X_val (1004, 5)\n",
      "X_test (744, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=.10)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=.15)\n",
    "print('X_train', X_train.shape)\n",
    "print('X_val', X_val.shape)\n",
    "print('X_test', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "7431    0\n",
      "7432    0\n",
      "7433    0\n",
      "7434    0\n",
      "7435    0\n",
      "Name: isdaftarulang, Length: 7436, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, ), activation='relu',max_iter=1000, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Validasi Training ANN: 0.8376494023904383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp.fit(X_train, Y_train)\n",
    "prediksi_val = mlp.predict(X_val)\n",
    "acc_val = accuracy_score(Y_val, prediksi_val)\n",
    "print('Akurasi Validasi Training ANN:', acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Testing ANN: 0.8172043010752689\n"
     ]
    }
   ],
   "source": [
    "prediksi_test = mlp.predict(X_test)\n",
    "acc_test = accuracy_score(Y_test, prediksi_test)\n",
    "print('Akurasi Testing ANN:', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Testing ANN: 0.8172043010752689\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "\n",
    "prediksi = mlp.predict(X_test)\n",
    "plot_confusion_matrix(mlp, X_test, Y_test)\n",
    "accuracy = accuracy_score(Y_test, prediksi)\n",
    "print('Akurasi Testing ANN:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(Y_train,2)\n",
    "Y_val = to_categorical(Y_val,2)\n",
    "Y_test = to_categorical(Y_test,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1138/1138 [==============================] - 3s 2ms/step - loss: 0.4986 - acc: 0.8010 - val_loss: 0.4911 - val_acc: 0.8058\n",
      "Epoch 2/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4871 - acc: 0.8073 - val_loss: 0.4875 - val_acc: 0.8058\n",
      "Epoch 3/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4827 - acc: 0.8073 - val_loss: 0.4918 - val_acc: 0.8058\n",
      "Epoch 4/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4782 - acc: 0.8073 - val_loss: 0.4794 - val_acc: 0.8058\n",
      "Epoch 5/100\n",
      "1138/1138 [==============================] - 3s 2ms/step - loss: 0.4737 - acc: 0.8073 - val_loss: 0.4775 - val_acc: 0.8058\n",
      "Epoch 6/100\n",
      "1138/1138 [==============================] - 3s 3ms/step - loss: 0.4675 - acc: 0.8073 - val_loss: 0.4705 - val_acc: 0.8058\n",
      "Epoch 7/100\n",
      "1138/1138 [==============================] - 3s 2ms/step - loss: 0.4619 - acc: 0.8073 - val_loss: 0.4663 - val_acc: 0.8058\n",
      "Epoch 8/100\n",
      "1138/1138 [==============================] - 3s 2ms/step - loss: 0.4575 - acc: 0.8073 - val_loss: 0.4592 - val_acc: 0.8058\n",
      "Epoch 9/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4532 - acc: 0.8073 - val_loss: 0.4566 - val_acc: 0.8058\n",
      "Epoch 10/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4479 - acc: 0.8073 - val_loss: 0.4544 - val_acc: 0.8058\n",
      "Epoch 11/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4456 - acc: 0.8073 - val_loss: 0.4487 - val_acc: 0.8058\n",
      "Epoch 12/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4422 - acc: 0.8073 - val_loss: 0.4518 - val_acc: 0.8058\n",
      "Epoch 13/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4384 - acc: 0.8073 - val_loss: 0.4507 - val_acc: 0.8058\n",
      "Epoch 14/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4358 - acc: 0.8073 - val_loss: 0.4373 - val_acc: 0.8058\n",
      "Epoch 15/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4325 - acc: 0.8077 - val_loss: 0.4358 - val_acc: 0.8058\n",
      "Epoch 16/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4305 - acc: 0.8078 - val_loss: 0.4327 - val_acc: 0.8058\n",
      "Epoch 17/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4286 - acc: 0.8128 - val_loss: 0.4308 - val_acc: 0.8058\n",
      "Epoch 18/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4264 - acc: 0.8180 - val_loss: 0.4288 - val_acc: 0.8088\n",
      "Epoch 19/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4246 - acc: 0.8219 - val_loss: 0.4274 - val_acc: 0.8257\n",
      "Epoch 20/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4234 - acc: 0.8244 - val_loss: 0.4314 - val_acc: 0.8367\n",
      "Epoch 21/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4222 - acc: 0.8270 - val_loss: 0.4355 - val_acc: 0.8376\n",
      "Epoch 22/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4198 - acc: 0.8284 - val_loss: 0.4231 - val_acc: 0.8367\n",
      "Epoch 23/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4206 - acc: 0.8291 - val_loss: 0.4242 - val_acc: 0.8376\n",
      "Epoch 24/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4199 - acc: 0.8288 - val_loss: 0.4229 - val_acc: 0.8376\n",
      "Epoch 25/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4199 - acc: 0.8296 - val_loss: 0.4229 - val_acc: 0.8357\n",
      "Epoch 26/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4182 - acc: 0.8298 - val_loss: 0.4229 - val_acc: 0.8367\n",
      "Epoch 27/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4188 - acc: 0.8312 - val_loss: 0.4208 - val_acc: 0.8376\n",
      "Epoch 28/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4182 - acc: 0.8305 - val_loss: 0.4492 - val_acc: 0.8396\n",
      "Epoch 29/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4190 - acc: 0.8309 - val_loss: 0.4301 - val_acc: 0.8376\n",
      "Epoch 30/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4172 - acc: 0.8305 - val_loss: 0.4196 - val_acc: 0.8376\n",
      "Epoch 31/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4183 - acc: 0.8307 - val_loss: 0.4190 - val_acc: 0.8376\n",
      "Epoch 32/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4182 - acc: 0.8305 - val_loss: 0.4210 - val_acc: 0.8376\n",
      "Epoch 33/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4179 - acc: 0.8303 - val_loss: 0.4233 - val_acc: 0.8327\n",
      "Epoch 34/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4182 - acc: 0.8312 - val_loss: 0.4230 - val_acc: 0.8376\n",
      "Epoch 35/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4176 - acc: 0.8303 - val_loss: 0.4232 - val_acc: 0.8376\n",
      "Epoch 36/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4170 - acc: 0.8305 - val_loss: 0.4205 - val_acc: 0.8376\n",
      "Epoch 37/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4183 - acc: 0.8307 - val_loss: 0.4190 - val_acc: 0.8376\n",
      "Epoch 38/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4181 - acc: 0.8314 - val_loss: 0.4196 - val_acc: 0.8376\n",
      "Epoch 39/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4172 - acc: 0.8307 - val_loss: 0.4242 - val_acc: 0.8376\n",
      "Epoch 40/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4166 - acc: 0.8302 - val_loss: 0.4187 - val_acc: 0.8376\n",
      "Epoch 41/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4175 - acc: 0.8305 - val_loss: 0.4206 - val_acc: 0.8376\n",
      "Epoch 42/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4165 - acc: 0.8310 - val_loss: 0.4197 - val_acc: 0.8376\n",
      "Epoch 43/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4170 - acc: 0.8303 - val_loss: 0.4191 - val_acc: 0.8376\n",
      "Epoch 44/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4172 - acc: 0.8309 - val_loss: 0.4208 - val_acc: 0.8376\n",
      "Epoch 45/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4164 - acc: 0.8310 - val_loss: 0.4199 - val_acc: 0.8376\n",
      "Epoch 46/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4167 - acc: 0.8307 - val_loss: 0.4229 - val_acc: 0.8376\n",
      "Epoch 47/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4166 - acc: 0.8314 - val_loss: 0.4231 - val_acc: 0.8376\n",
      "Epoch 48/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4176 - acc: 0.8314 - val_loss: 0.4201 - val_acc: 0.8376\n",
      "Epoch 49/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4169 - acc: 0.8298 - val_loss: 0.4209 - val_acc: 0.8376\n",
      "Epoch 50/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4168 - acc: 0.8309 - val_loss: 0.4247 - val_acc: 0.8376\n",
      "Epoch 51/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4161 - acc: 0.8307 - val_loss: 0.4185 - val_acc: 0.8376\n",
      "Epoch 52/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4170 - acc: 0.8305 - val_loss: 0.4265 - val_acc: 0.8386\n",
      "Epoch 53/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4174 - acc: 0.8298 - val_loss: 0.4192 - val_acc: 0.8376\n",
      "Epoch 54/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4159 - acc: 0.8305 - val_loss: 0.4255 - val_acc: 0.8376\n",
      "Epoch 55/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4174 - acc: 0.8309 - val_loss: 0.4189 - val_acc: 0.8376\n",
      "Epoch 56/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4169 - acc: 0.8310 - val_loss: 0.4208 - val_acc: 0.8376\n",
      "Epoch 57/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4157 - acc: 0.8312 - val_loss: 0.4286 - val_acc: 0.8317\n",
      "Epoch 58/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4169 - acc: 0.8305 - val_loss: 0.4208 - val_acc: 0.8376\n",
      "Epoch 59/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4165 - acc: 0.8307 - val_loss: 0.4186 - val_acc: 0.8376\n",
      "Epoch 60/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4160 - acc: 0.8309 - val_loss: 0.4194 - val_acc: 0.8376\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4157 - acc: 0.8319 - val_loss: 0.4209 - val_acc: 0.8376\n",
      "Epoch 62/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4175 - acc: 0.8310 - val_loss: 0.4409 - val_acc: 0.8367\n",
      "Epoch 63/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4167 - acc: 0.8312 - val_loss: 0.4240 - val_acc: 0.8376\n",
      "Epoch 64/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4161 - acc: 0.8312 - val_loss: 0.4344 - val_acc: 0.8376\n",
      "Epoch 65/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4169 - acc: 0.8312 - val_loss: 0.4194 - val_acc: 0.8376\n",
      "Epoch 66/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4171 - acc: 0.8312 - val_loss: 0.4202 - val_acc: 0.8376\n",
      "Epoch 67/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4175 - acc: 0.8305 - val_loss: 0.4185 - val_acc: 0.8376\n",
      "Epoch 68/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4168 - acc: 0.8309 - val_loss: 0.4211 - val_acc: 0.8376\n",
      "Epoch 69/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4149 - acc: 0.8302 - val_loss: 0.4183 - val_acc: 0.8376\n",
      "Epoch 70/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4178 - acc: 0.8309 - val_loss: 0.4186 - val_acc: 0.8376\n",
      "Epoch 71/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4158 - acc: 0.8303 - val_loss: 0.4206 - val_acc: 0.8376\n",
      "Epoch 72/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4164 - acc: 0.8307 - val_loss: 0.4188 - val_acc: 0.8376\n",
      "Epoch 73/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4159 - acc: 0.8302 - val_loss: 0.4321 - val_acc: 0.8376\n",
      "Epoch 74/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4156 - acc: 0.8312 - val_loss: 0.4184 - val_acc: 0.8376\n",
      "Epoch 75/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4167 - acc: 0.8316 - val_loss: 0.4192 - val_acc: 0.8376\n",
      "Epoch 76/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4156 - acc: 0.8300 - val_loss: 0.4210 - val_acc: 0.8376\n",
      "Epoch 77/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4167 - acc: 0.8305 - val_loss: 0.4204 - val_acc: 0.8376\n",
      "Epoch 78/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4169 - acc: 0.8307 - val_loss: 0.4183 - val_acc: 0.8376\n",
      "Epoch 79/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4169 - acc: 0.8300 - val_loss: 0.4368 - val_acc: 0.8386\n",
      "Epoch 80/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4153 - acc: 0.8325 - val_loss: 0.4575 - val_acc: 0.8058\n",
      "Epoch 81/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4173 - acc: 0.8310 - val_loss: 0.4209 - val_acc: 0.8376\n",
      "Epoch 82/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4167 - acc: 0.8309 - val_loss: 0.4339 - val_acc: 0.8376\n",
      "Epoch 83/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4164 - acc: 0.8303 - val_loss: 0.4188 - val_acc: 0.8376\n",
      "Epoch 84/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4168 - acc: 0.8309 - val_loss: 0.4190 - val_acc: 0.8376\n",
      "Epoch 85/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4166 - acc: 0.8303 - val_loss: 0.4199 - val_acc: 0.8376\n",
      "Epoch 86/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4169 - acc: 0.8305 - val_loss: 0.4235 - val_acc: 0.8376\n",
      "Epoch 87/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4161 - acc: 0.8307 - val_loss: 0.4240 - val_acc: 0.8376\n",
      "Epoch 88/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4159 - acc: 0.8316 - val_loss: 0.4179 - val_acc: 0.8376\n",
      "Epoch 89/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4171 - acc: 0.8305 - val_loss: 0.4201 - val_acc: 0.8376\n",
      "Epoch 90/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4153 - acc: 0.8307 - val_loss: 0.4206 - val_acc: 0.8376\n",
      "Epoch 91/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4161 - acc: 0.8309 - val_loss: 0.4506 - val_acc: 0.8147\n",
      "Epoch 92/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4151 - acc: 0.8307 - val_loss: 0.4237 - val_acc: 0.8376\n",
      "Epoch 93/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4157 - acc: 0.8310 - val_loss: 0.4195 - val_acc: 0.8376\n",
      "Epoch 94/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4136 - acc: 0.8300 - val_loss: 0.4253 - val_acc: 0.8376\n",
      "Epoch 95/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4155 - acc: 0.8309 - val_loss: 0.4189 - val_acc: 0.8376\n",
      "Epoch 96/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4155 - acc: 0.8314 - val_loss: 0.4188 - val_acc: 0.8376\n",
      "Epoch 97/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4157 - acc: 0.8307 - val_loss: 0.4176 - val_acc: 0.8376\n",
      "Epoch 98/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4148 - acc: 0.8305 - val_loss: 0.4349 - val_acc: 0.8367\n",
      "Epoch 99/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4150 - acc: 0.8310 - val_loss: 0.4191 - val_acc: 0.8376\n",
      "Epoch 100/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.4160 - acc: 0.8314 - val_loss: 0.4196 - val_acc: 0.8376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3ed3f09d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=100,batch_size=5,validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                384       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 514\n",
      "Trainable params: 514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4183 - acc: 0.8172\n",
      "Akurasi Testing ANN: 0.8172042965888977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print('Akurasi Testing ANN:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook DTS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
